{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Intro\n",
    "* https://keras.io/applications/\n",
    "* http://www.image-net.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from distutils.version import StrictVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "assert StrictVersion(sklearn.__version__ ) >= StrictVersion('0.18.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print(tf.__version__)\n",
    "\n",
    "assert StrictVersion(tf.__version__) >= StrictVersion('1.1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "assert StrictVersion(keras.__version__) >= StrictVersion('2.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell-Architektur\n",
    "http://cs231n.github.io/neural-networks-1/#power\n",
    "\n",
    "### Layout of a typical CNN\n",
    "\n",
    "![Layout of a typical CNN](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/convnet-layoyt.jpeg)\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "### Classic VGG like Architecture\n",
    "* we use a VGG like architecture\n",
    "* based on https://arxiv.org/abs/1409.1556\n",
    "* basic idea: sequential, deep, small convolutional filters, use dropouts to reduce overfitting\n",
    "* 16/19 layers are typical\n",
    "* we choose less layers, because we have limited resources\n",
    "\n",
    "### Convolutional Blocks: Cascading many Convolutional Layers having down sampling in between\n",
    "\n",
    "![Applying filters](http://cs231n.github.io/assets/cnn/cnn.jpeg)\n",
    "\n",
    "http://cs231n.github.io/convolutional-networks/#conv\n",
    "\n",
    "### Example of a Convolution\n",
    "#### Original Image\n",
    "![Dog](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/conv/dog.png)\n",
    "#### Many convolutional filters applied over all channels\n",
    "![Dog after Convolutional Filters applied](https://github.com/DJCordhose/speed-limit-signs/raw/master/img/conv/dog-conv1.png)\n",
    "http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html\n",
    "\n",
    "### Downlsampling Layer: Reduces data sizes and risk of overfitting\n",
    "![Pooling](http://cs231n.github.io/assets/cnn/pool.jpeg)\n",
    "![Max Pooling](http://cs231n.github.io/assets/cnn/maxpool.jpeg)\n",
    "http://cs231n.github.io/convolutional-networks/#pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centerAxis(uses_negative=False):\n",
    "    # http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_position('center')\n",
    "    if uses_negative:\n",
    "        ax.spines['bottom'].set_position('center')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid\n",
    "* This is the classic\n",
    "* Continuous version of step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_sigmoid(X):\n",
    "    return 1 / (1 + np.exp(X * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fdaa43518>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEACAYAAACTXJylAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2fdaa43438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10,10,0.01)\n",
    "y = np_sigmoid(x)\n",
    "\n",
    "centerAxis()\n",
    "plt.plot(x,y,lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu\n",
    "* perfect for blacking out everyhing beyong threshold\n",
    "* this is just what everyone actually uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2fdaa21f98>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEACAYAAACTXJylAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wftR2BQN/ShFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2fdaa21f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10, 10, 0.01)\n",
    "y = np_relu(x)\n",
    "\n",
    "centerAxis()\n",
    "plt.plot(x,y,lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The classic VGG16 Architecture\n",
    "![NN Architecture](https://djcordhose.github.io/ai/img/flashcards/Architecture_Of_A_Neural_Network_print.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    # decode the results into a list of tuples (class, description, probability)\n",
    "    # (one such list for each sample in the batch)\n",
    "    print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "# applications.VGG16?\n",
    "vgg16_model = applications.VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG starts with a number of convolutional blocks for feature extraction and ends with a fully connected classifier\n",
    "![VGG architecture](https://djcordhose.github.io/ai/img/sketch/vgg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r\n",
      "curl: (56) Received HTTP code 403 from proxy after CONNECT\r\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Beagle_Upsy.jpg/440px-Beagle_Upsy.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Beagle](https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Beagle_Upsy.jpg/440px-Beagle_Upsy.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02088364', 'beagle', 0.32020867), ('n02089973', 'English_foxhound', 0.26515135), ('n02089867', 'Walker_hound', 0.20564148)]\n"
     ]
    }
   ],
   "source": [
    "predict(model = vgg16_model, img_path = '440px-Beagle_Upsy.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  843k  100  843k    0     0  1917k      0 --:--:-- --:--:-- --:--:-- 1916k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://djcordhose.github.io/ai/img/cat-bonkers.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02124075', 'Egyptian_cat', 0.93594509), ('n02123045', 'tabby', 0.040695436), ('n02123159', 'tiger_cat', 0.019523595)]\n"
     ]
    }
   ],
   "source": [
    "predict(model = vgg16_model, img_path = 'cat-bonkers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  126k  100  126k    0     0   659k      0 --:--:-- --:--:-- --:--:--  664k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  302k  100  302k    0     0  1314k      0 --:--:-- --:--:-- --:--:-- 1314k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  494k  100  494k    0     0  1143k      0 --:--:-- --:--:-- --:--:-- 1152k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://djcordhose.github.io/ai/img/squirrels/original/Michigan-MSU-raschka.jpg\n",
    "!curl -O https://djcordhose.github.io/ai/img/squirrels/original/Black_New_York_stuy_town_squirrel_amanda_ernlund.jpeg\n",
    "!curl -O https://djcordhose.github.io/ai/img/squirrels/original/london.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Squirrel 1: Michigan MSU](https://djcordhose.github.io/ai/img/squirrels/original/Michigan-MSU-raschka.jpg)\n",
    "![Squirrel 2: Stuy Town](https://djcordhose.github.io/ai/img/squirrels/original/Black_New_York_stuy_town_squirrel_amanda_ernlund.jpeg)\n",
    "![Squirrel 3: London](https://djcordhose.github.io/ai/img/squirrels/original/london.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02356798', 'fox_squirrel', 0.99995279), ('n02361337', 'marmot', 4.3569533e-05), ('n02120505', 'grey_fox', 2.3456425e-06)]\n"
     ]
    }
   ],
   "source": [
    "predict(model = vgg16_model, img_path = 'Michigan-MSU-raschka.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n01514859', 'hen', 0.251127), ('n01514668', 'cock', 0.13989805), ('n02486410', 'baboon', 0.13570367)]\n"
     ]
    }
   ],
   "source": [
    "predict(model = vgg16_model, img_path = 'Black_New_York_stuy_town_squirrel_amanda_ernlund.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02655020', 'puffer', 0.21103905), ('n02441942', 'weasel', 0.085964032), ('n01950731', 'sea_slug', 0.06110343)]\n"
     ]
    }
   ],
   "source": [
    "predict(model = vgg16_model, img_path = 'london.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the CNN \"see\"?\n",
    "### Does it \"see\" the right thing?\n",
    "* Each filter output of a convolutional layer is called *feature channel*\n",
    "* with each input they should ideally either be\n",
    "  * blank if they do not recognize any feature in the input or\n",
    "  * encode what the feature channel \"sees\" in the input\n",
    "* feature channels directly before FC layers are often called *bottleneck feature channels*\n",
    "\n",
    "### Some activations from bottleneck features:\n",
    "![Beagle Activation](https://github.com/DJCordhose/ai/raw/master/docs/img/conv/where-is-the-beagle.png)\n",
    "![Squirrel Activation](https://github.com/DJCordhose/ai/raw/master/docs/img/conv/where-is-the-squirrel.png)\n",
    "![Cat Activation](https://github.com/DJCordhose/ai/raw/master/docs/img/conv/where-is-bonkers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a tmp dir in the local directory this notebook runs in, otherwise quiver will fail (and won't tell you why)\n",
    "!rm -rf tmp\n",
    "!mkdir tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing feature channels using Quiver\n",
    "### Only works locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'quiver_engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-85b6fa938e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# https://github.com/keplr-io/quiver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mquiver_engine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'quiver_engine'"
     ]
    }
   ],
   "source": [
    "# https://github.com/keplr-io/quiver\n",
    "\n",
    "# Alternative with more styles of visualization: https://github.com/raghakot/keras-vis\n",
    "\n",
    "# https://github.com/keplr-io/quiver\n",
    "# from quiver_engine import server\n",
    "# server.launch(vgg16_model, input_folder='.', port=7000)\n",
    "\n",
    "# open at http://localhost:7000/\n",
    "# interrupt kernel to return control to notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern Alternative: Resnet\n",
    "* https://keras.io/applications/#resnet50\n",
    "* https://arxiv.org/abs/1512.03385\n",
    "* New Layer Type: https://keras.io/layers/normalization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "resnet_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(model = resnet_model, img_path = 'cat-bonkers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(model = resnet_model, img_path = 'Michigan-MSU-raschka.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(model = resnet_model, img_path = 'Black_New_York_stuy_town_squirrel_amanda_ernlund.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(model = resnet_model, img_path = 'london.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hands-On 1 (CNN Overview)\n",
    "## Experiment with all Kinds of Layers: https://transcranial.github.io/keras-js/#/mnist-cnn\n",
    "![Keras Browser](https://djcordhose.github.io/ai/img/browser/keras-browser.png)\n",
    "* Try to fool the network by incrementally drawing ambiguous digits\n",
    "\n",
    "__Side Node__: Keras.js makes all Keras Models available in the Browser\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hands-On 2 (Filter Kernel Details)\n",
    "## Try out Filter Kernels: http://setosa.io/ev/image-kernels/\n",
    "![Image Kernels](https://djcordhose.github.io/ai/img/browser/setosa_io_image-kernels.png)\n",
    "* Try out Filter Kernels Sharpen and Blur on a speed limit sign: https://github.com/DJCordhose/speed-limit-signs/raw/master/data/real-world/4/100-sky-cutoff-detail.jpg\n",
    "* Create a custom filter\n",
    "\n",
    "![100 Speed Limit Sign](https://github.com/DJCordhose/speed-limit-signs/raw/master/data/real-world/4/100-sky-cutoff-detail.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
